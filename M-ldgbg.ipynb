{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccee0302",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Imports & settings\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from matplotlib.patches import Circle\n",
    "from scipy.spatial.distance import cdist\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder, MinMaxScaler, StandardScaler\n",
    "from sklearn.model_selection import train_test_split, KFold\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, classification_report\n",
    "from sklearn.decomposition import PCA\n",
    " \n",
    "sns.set(style=\"whitegrid\")\n",
    "np.random.seed(42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61e573e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_and_normalize(df, label_col=None, normalize=True):\n",
    "    dfc = df.copy()\n",
    "\n",
    "    # If label col not given -> assume last\n",
    "    if label_col is None:\n",
    "        label_col = dfc.columns[-1]\n",
    "\n",
    "    # Remove ID-like columns\n",
    "    for col in list(dfc.columns):\n",
    "        if (\n",
    "            dfc[col].dtype == object \n",
    "            and dfc[col].nunique() == dfc.shape[0] \n",
    "            and col != label_col\n",
    "        ):\n",
    "            dfc = dfc.drop(columns=[col])\n",
    "\n",
    "    # Fill missing values safely (NO inplace)\n",
    "    for col in dfc.columns:\n",
    "        if dfc[col].dtype == object:\n",
    "            dfc[col] = dfc[col].fillna(dfc[col].mode()[0])\n",
    "        else:\n",
    "            dfc[col] = dfc[col].fillna(dfc[col].median())\n",
    "\n",
    "    # Separate X, y\n",
    "    X_df = dfc.drop(columns=[label_col])\n",
    "    y_df = dfc[label_col]\n",
    "\n",
    "    # Encode categorical features\n",
    "    for col in X_df.columns:\n",
    "        if X_df[col].dtype == object:\n",
    "            X_df[col] = LabelEncoder().fit_transform(X_df[col])\n",
    "\n",
    "    # Encode label\n",
    "    if y_df.dtype == object:\n",
    "        y_df = LabelEncoder().fit_transform(y_df)\n",
    "    else:\n",
    "        y_df = y_df.values\n",
    "\n",
    "    # Normalization check\n",
    "    if normalize:\n",
    "        num_cols = X_df.select_dtypes(include=[np.number]).columns\n",
    "        mins = X_df[num_cols].min()\n",
    "        maxs = X_df[num_cols].max()\n",
    "\n",
    "        is_norm = np.all((mins >= 0.0) & (maxs <= 1.0))\n",
    "\n",
    "        if not is_norm:\n",
    "            scaler = MinMaxScaler()\n",
    "            X_df[num_cols] = scaler.fit_transform(X_df[num_cols])\n",
    "\n",
    "    return X_df.values.astype(float), np.array(y_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a573a0d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#LDGBG implementation\n",
    "class LDGBG:\n",
    "    def __init__(self, g=1.0, sparsity_threshold=40.0, target_fraction=0.015):\n",
    "        self.g = float(g)\n",
    "        self.sparsity_threshold = float(sparsity_threshold)\n",
    "        self.target_fraction = float(target_fraction)\n",
    "        self.granular_balls = []\n",
    "        self.delta_ = None\n",
    "        self.dc_ = None\n",
    "\n",
    "    # compute dc by scanning distances to satisfy avg neighbors ~ target_fraction*n\n",
    "    def _compute_dc(self, X):\n",
    "        N = len(X)\n",
    "        D = cdist(X, X)\n",
    "        flat = np.sort(D[np.triu_indices(N, k=1)])\n",
    "        if len(flat) == 0:\n",
    "            return 1e-6\n",
    "        desired = max(1, int(self.target_fraction * N))\n",
    "        best_dc = None\n",
    "        best_err = float('inf')\n",
    "        # scan candidate distances (use subset of percentiles for speed)\n",
    "        ps = np.linspace(1, 99, 99)\n",
    "        for p in ps:\n",
    "            dc = np.percentile(flat, p)\n",
    "            neighbors = (D <= dc).sum(axis=1) - 1  # exclude self\n",
    "            avg = neighbors.mean()\n",
    "            err = abs(avg - desired)\n",
    "            if err < best_err:\n",
    "                best_err = err\n",
    "                best_dc = dc\n",
    "        if best_dc is None:\n",
    "            best_dc = np.percentile(flat, 2.0)\n",
    "        return float(best_dc)\n",
    "\n",
    "    # local density (rho) as gaussian sum + neighbor count\n",
    "    def _local_density(self, X, delta):\n",
    "        D = cdist(X, X)\n",
    "        gaussian = np.exp(- (D / (delta + 1e-12)) ** 2)\n",
    "        neighbors = (D <= delta).astype(float)\n",
    "        rho = gaussian.sum(axis=1) + neighbors.sum(axis=1)\n",
    "        return rho, D\n",
    "\n",
    "    # outlier rule\n",
    "    def _is_outlier(self, rho_i, rho_max, neigh_count, is_sparse):\n",
    "        if not is_sparse and neigh_count <= 1:\n",
    "            return True\n",
    "        if rho_i < 0.01 * rho_max:\n",
    "            return True\n",
    "        return False\n",
    "\n",
    "    # generate centers per class(density peaks, mark neighbors used)\n",
    "    def _generate_centers_for_class(self, Xc, delta, is_sparse):\n",
    "        if Xc.shape[0] == 0:\n",
    "            return [], []\n",
    "        rho, D = self._local_density(Xc, delta)\n",
    "        rho_max = rho.max()\n",
    "        used = np.zeros(len(Xc), dtype=bool)\n",
    "        centers = []\n",
    "        densities = []\n",
    "        # iterate by density descending\n",
    "        for idx in np.argsort(rho)[::-1]:\n",
    "            if used[idx]:\n",
    "                continue\n",
    "            neigh_mask = (D[idx] <= delta)\n",
    "            neigh_count = neigh_mask.sum()\n",
    "            if self._is_outlier(rho[idx], rho_max, neigh_count, is_sparse):\n",
    "                used[idx] = True\n",
    "                rho[idx] = 0.0\n",
    "                continue\n",
    "            # select center\n",
    "            centers.append(Xc[idx])\n",
    "            densities.append(rho[idx])\n",
    "            # zero densities for center & neighbors\n",
    "            rho[neigh_mask] = 0.0\n",
    "            used[neigh_mask] = True\n",
    "        return centers, densities\n",
    "\n",
    "    # radius computation\n",
    "    def _compute_radii(self, centers, labels, dens, delta):\n",
    "        if len(centers) == 0:\n",
    "            return np.array([])\n",
    "        C = np.array(centers)\n",
    "        if len(C) == 1:\n",
    "            return np.array([delta / 2.0])\n",
    "        D = cdist(C, C)\n",
    "        radii = []\n",
    "        for i in range(len(C)):\n",
    "            row = D[i].copy()\n",
    "            row[i] = np.inf\n",
    "            j = int(np.argmin(row))\n",
    "            Dij = row[j]\n",
    "            rho_i, rho_j = dens[i], dens[j]\n",
    "            li, lj = labels[i], labels[j]\n",
    "            if li == lj or rho_i > rho_j:\n",
    "                r = Dij / 2.0\n",
    "            else:\n",
    "                r = (Dij / 2.0) * (rho_i / (rho_i + rho_j + 1e-12))\n",
    "            radii.append(r)\n",
    "        return np.array(radii)\n",
    "\n",
    "    # fit method\n",
    "    def fit(self, X, y):\n",
    "        X = np.asarray(X, dtype=float)\n",
    "        y = np.asarray(y)\n",
    "        n, m = X.shape\n",
    "        is_sparse = (n / m) < self.sparsity_threshold\n",
    "        # compute dc & delta\n",
    "        dc = self._compute_dc(X)\n",
    "        delta = self.g * dc\n",
    "        self.dc_ = dc\n",
    "        self.delta_ = delta\n",
    "        centers_all = []\n",
    "        dens_all = []\n",
    "        labels_all = []\n",
    "        # per-class centers\n",
    "        for cls in np.unique(y):\n",
    "            Xc = X[y == cls]\n",
    "            centers, dens = self._generate_centers_for_class(Xc, delta, is_sparse)\n",
    "            centers_all.extend(centers)\n",
    "            dens_all.extend(dens)\n",
    "            labels_all.extend([cls] * len(centers))\n",
    "        if len(centers_all) == 0:\n",
    "            # fallback: choose a few highest-density samples per class\n",
    "            self.granular_balls = []\n",
    "            return self\n",
    "        radii = self._compute_radii(centers_all, labels_all, dens_all, delta)\n",
    "        # store granular balls\n",
    "        self.granular_balls = [\n",
    "            {\"center\": np.array(centers_all[i], dtype=float),\n",
    "             \"radius\": float(radii[i]),\n",
    "             \"label\": labels_all[i],\n",
    "             \"density\": float(dens_all[i])}\n",
    "            for i in range(len(centers_all))\n",
    "        ]\n",
    "        return self\n",
    "\n",
    "    def get_granular_balls(self):\n",
    "        return self.granular_balls\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67c4ed2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#LDGBKNN classifier\n",
    "class LDGBKNN:\n",
    "    def fit(self, X, y):\n",
    "        self.model = LDGBG()\n",
    "        self.model.fit(X, y)\n",
    "        return self\n",
    "\n",
    "    def _dist_to_ball(self, x, gb):\n",
    "        return max(0.0, np.linalg.norm(x - gb[\"center\"]) - gb[\"radius\"])\n",
    "\n",
    "    def predict(self, X):\n",
    "        X = np.asarray(X, dtype=float)\n",
    "        gbs = self.model.get_granular_balls()\n",
    "        if len(gbs) == 0:\n",
    "            # fallback: majority label\n",
    "            return np.full(X.shape[0], -1)\n",
    "        preds = []\n",
    "        for x in X:\n",
    "            best_gb = min(gbs, key=lambda gb: self._dist_to_ball(x, gb))\n",
    "            preds.append(best_gb[\"label\"])\n",
    "        return np.array(preds)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4528dd03",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Plotting\n",
    "def plot_density_pca(X, rho, y=None, ax=None, cmap='viridis', title='Local density (ρ)'):\n",
    "    if ax is None:\n",
    "        fig, ax = plt.subplots(figsize=(6,6))\n",
    "    pca = PCA(n_components=2)\n",
    "    X2 = pca.fit_transform(X)\n",
    "    sc = ax.scatter(X2[:,0], X2[:,1], c=rho, cmap=cmap, s=18, alpha=0.9)\n",
    "    ax.set_title(title)\n",
    "    plt.colorbar(sc, ax=ax, label='rho')\n",
    "    return pca, X2, ax\n",
    "\n",
    "def plot_centers_pca(pca, centers, ax=None, color='red', label='centers'):\n",
    "    if ax is None:\n",
    "        fig, ax = plt.subplots(figsize=(6,6))\n",
    "    C2 = pca.transform(np.array(centers))\n",
    "    ax.scatter(C2[:,0], C2[:,1], c=color, s=80, marker='X', edgecolor='k', label=label)\n",
    "    return ax\n",
    "\n",
    "def plot_gb_memberships_pca(pca, X, gbs, y=None, ax=None, scale_radius=True):\n",
    "    if ax is None:\n",
    "        fig, ax = plt.subplots(figsize=(7,7))\n",
    "    X2 = pca.transform(X)\n",
    "    # plot all points faintly\n",
    "    ax.scatter(X2[:,0], X2[:,1], c='lightgrey', s=12, alpha=0.5)\n",
    "    for gb in gbs:\n",
    "        center = gb['center']\n",
    "        members_mask = np.linalg.norm(X - center, axis=1) <= gb['radius']\n",
    "        Xm2 = pca.transform(X[members_mask])\n",
    "        ax.scatter(Xm2[:,0], Xm2[:,1], s=18, alpha=0.7)\n",
    "        cx, cy = pca.transform([center])[0]\n",
    "        # scale radius heuristically for PCA projection\n",
    "        if scale_radius:\n",
    "            scale = pca.explained_variance_ratio_.mean()\n",
    "            r_plot = gb['radius'] * scale\n",
    "        else:\n",
    "            r_plot = gb['radius']\n",
    "        circle = Circle((cx, cy), r_plot, fill=False, edgecolor='black', linewidth=1.0)\n",
    "        ax.add_patch(circle)\n",
    "        ax.plot(cx, cy, 'ko', markersize=4)\n",
    "    ax.set_title('Granular-balls and member points (PCA projected)')\n",
    "    return ax\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6069cb77",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Robustness over multiple noise levels & stability across multiple random splits\n",
    "def compute_robustness(model, X_test, y_test, noise_levels=[0.05,0.1,0.15,0.2], repeats=5):\n",
    "    accs = []\n",
    "    for sigma in noise_levels:\n",
    "        run_accs = []\n",
    "        for _ in range(repeats):\n",
    "            X_noisy = X_test + np.random.normal(0, sigma, X_test.shape)\n",
    "            y_pred_noisy = model.predict(X_noisy)\n",
    "            run_accs.append(accuracy_score(y_test, y_pred_noisy))\n",
    "        accs.append(np.mean(run_accs))\n",
    "    # robustness = average noisy accuracy relative to clean accuracy? Paper uses degradation; we'll return mean noisy accuracy\n",
    "    return float(np.mean(accs)), accs\n",
    "\n",
    "def compute_stability(model_cls, X, y, runs=10, test_size=0.3):\n",
    "    accs = []\n",
    "    for i in range(runs):\n",
    "        X_tr, X_ts, y_tr, y_ts = train_test_split(X, y, test_size=test_size, random_state= i*7 + 13)\n",
    "        mdl = model_cls().fit(X_tr, y_tr)\n",
    "        y_p = mdl.predict(X_ts)\n",
    "        accs.append(accuracy_score(y_ts, y_p))\n",
    "    mean_acc = float(np.mean(accs))\n",
    "    var_acc = float(np.var(accs))\n",
    "    stability = 1.0 - var_acc  # heuristic as used earlier\n",
    "    return mean_acc, stability, accs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a7860c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate (fit, metrics, robustness, stability, visualizations)\n",
    "def evaluate_dataset(df, label_col=None, normalize=True, verbose=True, noise_levels=[0.05,0.1,0.15,0.2]):\n",
    "    X, y = clean_and_normalize(df, label_col=label_col, normalize=normalize)\n",
    "    # train-test\n",
    "    X_tr, X_ts, y_tr, y_ts = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "    # train\n",
    "    clf = LDGBKNN().fit(X_tr, y_tr)\n",
    "    y_pred = clf.predict(X_ts)\n",
    "    # core metrics\n",
    "    acc = accuracy_score(y_ts, y_pred)\n",
    "    prec = precision_score(y_ts, y_pred, average='macro', zero_division=0)\n",
    "    rec = recall_score(y_ts, y_pred, average='macro', zero_division=0)\n",
    "    f1 = f1_score(y_ts, y_pred, average='macro', zero_division=0)\n",
    "    # robustness (mean noisy accuracy and per-level)\n",
    "    mean_noisy_acc, per_level = compute_robustness(clf, X_ts, y_ts, noise_levels=noise_levels, repeats=5)\n",
    "    # stability\n",
    "    mean_cv_acc, stability, accs_cv = compute_stability(LDGBKNN, X, y, runs=8, test_size=0.3)\n",
    "    # get granular balls and density for plotting\n",
    "    gbs = clf.model.get_granular_balls()\n",
    "    # compute density on full X using delta from model if available\n",
    "    rho = None\n",
    "    pca = PCA(n_components=2)\n",
    "    pca.fit(X)  # used for visual transform\n",
    "    if hasattr(clf.model, 'delta_') and clf.model.delta_ is not None:\n",
    "        try:\n",
    "            rho, _ = clf.model._local_density(X, clf.model.delta_)\n",
    "        except Exception:\n",
    "            rho = None\n",
    "\n",
    "    metrics = {\n",
    "        'accuracy': acc,\n",
    "        'precision': prec,\n",
    "        'recall': rec,\n",
    "        'f1': f1,\n",
    "        'robustness_mean_noisy_acc': mean_noisy_acc,\n",
    "        'robustness_per_level': per_level,\n",
    "        'stability': stability,\n",
    "        'stability_accs': accs_cv,\n",
    "        'num_gbs': len(gbs),\n",
    "        'gbs': gbs,\n",
    "        'X': X,\n",
    "        'y': y,\n",
    "        'pca': pca,\n",
    "        'rho': rho\n",
    "    }\n",
    "\n",
    "    if verbose:\n",
    "        print(\"Accuracy: {:.4f}, Precision: {:.4f}, Recall: {:.4f}, F1: {:.4f}\".format(acc, prec, rec, f1))\n",
    "        print(\"Robustness (avg noisy acc): {:.4f}, per levels: {}\".format(mean_noisy_acc, np.round(per_level,4)))\n",
    "        print(\"Stability (1-var accs): {:.4f}, accs: {}\".format(stability, np.round(accs_cv,4)))\n",
    "        print(\"Number of Granular Balls:\", len(gbs))\n",
    "    return metrics\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4be39489",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Run multiple datasets\n",
    "def evaluate_multiple_datasets(dataset_paths, label_cols=None, normalize=True):\n",
    "    all_metrics = []\n",
    "    for i, path in enumerate(dataset_paths):\n",
    "        print(\"Dataset:\", path)\n",
    "        df = pd.read_csv(path)\n",
    "         # Dataset info\n",
    "        print(\"Shape:\", df.shape)\n",
    "        label_col = None\n",
    "        if label_cols and i < len(label_cols):\n",
    "            label_col = label_cols[i]\n",
    "        metrics = evaluate_dataset(df, label_col=label_col, normalize=normalize, verbose=True)\n",
    "        metrics['dataset'] = path\n",
    "        all_metrics.append(metrics)\n",
    "\n",
    "        # per-dataset visuals (3-paper figures)\n",
    "        X = metrics['X']; y = metrics['y']; pca = metrics['pca']; gbs = metrics['gbs']; rho = metrics['rho']\n",
    "        fig, axs = plt.subplots(1,3, figsize=(18,5))\n",
    "        # 1. density\n",
    "        if rho is not None:\n",
    "            plot_density_pca(X, rho, ax=axs[0], title=f\"{path} - Local density (ρ)\")\n",
    "        else:\n",
    "            axs[0].scatter(pca.transform(X)[:,0], pca.transform(X)[:,1], c=y, s=18)\n",
    "            axs[0].set_title(f\"{path} - PCA colored by class (ρ not available)\")\n",
    "        # 2. centers\n",
    "        axs[1].scatter(pca.transform(X)[:,0], pca.transform(X)[:,1], c=y, s=18, alpha=0.5)\n",
    "        if len(gbs) > 0:\n",
    "            centers = [gb['center'] for gb in gbs]\n",
    "            plot_centers_pca(pca, centers, ax=axs[1], color='red')\n",
    "        axs[1].set_title(f\"{path} - Centers (PCA)\")\n",
    "        # 3. granular ball membership\n",
    "        plot_gb_memberships_pca(pca, X, gbs, ax=axs[2])\n",
    "        plt.suptitle(f\"LDGBG Visuals for {path}\")\n",
    "        plt.show()\n",
    "\n",
    "    # compute averages across metrics\n",
    "    dfm = pd.DataFrame([\n",
    "        {\n",
    "            'dataset': m['dataset'],\n",
    "            'accuracy': m['accuracy'],\n",
    "            'precision': m['precision'],\n",
    "            'recall': m['recall'],\n",
    "            'f1': m['f1'],\n",
    "            'robustness': m['robustness_mean_noisy_acc'],\n",
    "            'stability': m['stability'],\n",
    "            'num_gbs': m['num_gbs']\n",
    "        } for m in all_metrics\n",
    "    ])\n",
    "    avg_row = dfm.mean(numeric_only=True)\n",
    "    print(\"\\n=== Average metrics across datasets ===\")\n",
    "    display(avg_row)\n",
    "\n",
    "    # bar plots for averages\n",
    "    plt.figure(figsize=(10,5))\n",
    "    avg_row[['accuracy','precision','recall','f1','robustness','stability']].plot(kind='bar')\n",
    "    plt.title(\"Average Metrics Across Datasets\")\n",
    "    plt.ylim(0,1.05)\n",
    "    plt.show()\n",
    "\n",
    "    return all_metrics, dfm, avg_row\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "053c60c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#dataset list\n",
    "dataset_list = [\n",
    "    \"Sonar.csv\",\n",
    "    \"Zoo.csv\",\n",
    "    \"seeds.csv\",\n",
    "    \"dermatology.csv\",\n",
    "    \"breast_cancer.csv\",\n",
    "    \"ionosphere.csv\",\n",
    "    \"Thyroid1.csv\"\n",
    "]\n",
    "\n",
    "\n",
    "all_metrics, metrics_df, avg_metrics = evaluate_multiple_datasets(dataset_list, normalize=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88b1f4a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Save per-dataset metrics to CSV\n",
    "metrics_df.to_csv(\"LDGBG_Data.csv\", index=False)\n",
    "print(\"Saved metrics to LDGBG_DATA.csv\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv (3.13.2)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
